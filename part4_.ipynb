{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1687553093599},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"machine_shape":"hm","collapsed_sections":["ukL5T9GH8DZG","SDhK-NfBwYtF","-CMu8fdN1axG","y5riTAtW34oP"],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4cbgwZWWfWpp"},"source":["# Libaries"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"5i30f7VGqdE6","executionInfo":{"status":"ok","timestamp":1687883466932,"user_tz":-330,"elapsed":17952,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"774a80de-f696-4269-9338-e7c87790c16c","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"pafL7Li0jyXW"},"source":["import os\n","import librosa\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import adjusted_rand_score\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import silhouette_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import tensorflow as tf\n","import librosa as lr\n","import soundfile as sf\n","import scipy.signal as sig\n","from random import random, randint, shuffle\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install librosa"],"metadata":{"id":"owL8wdTo7zEl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Global Code"],"metadata":{"id":"iwcRmAc6LLJB"}},{"cell_type":"code","source":["dataset_dir = '/content/drive/MyDrive/iit_our_rec/'\n","ambient_path = '/content/drive/MyDrive/iit_our_rec/noise_30min.wav'"],"metadata":{"id":"x9eT9fL9MR1s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name):\n","    if model_name == 'SVM':\n","        model = SVC(C=10, kernel='rbf', gamma='scale')\n","    elif model_name == 'Random Forest':\n","        model = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif model_name == 'Naive Bayes':\n","        model = GaussianNB()\n","    elif model_name == 'Decision Trees':\n","        model = DecisionTreeClassifier(random_state=42)\n","    elif model_name == 'k-Nearest Neighbors':\n","        model = KNeighborsClassifier(n_neighbors=5)\n","\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    confusion_mat = confusion_matrix(y_test, y_pred)\n","\n","    print(\"Model:\", model_name)\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Precision:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1 Score:\", f1)\n","    print(\"Confusion Matrix:\")\n","    print(confusion_mat)\n","    print(\"\\n\")"],"metadata":{"id":"I2RWRHa5LItg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_names = ['SVM', 'Random Forest', 'Naive Bayes', 'Decision Trees', 'k-Nearest Neighbors']\n"],"metadata":{"id":"N2xuEAyUQkWE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"awIcG59ERqy3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mel spec"],"metadata":{"id":"DauMDdLR779t"}},{"cell_type":"code","source":["def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit, n_mels):\n","    audio_data = []\n","    mel_spec_data = []\n","    labels = []\n","    duration = 1\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=1747)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    audio_data.append(adjusted_audio_signal)\n","\n","                    segment_mel_spec = librosa.feature.melspectrogram(\n","                        y=adjusted_audio_signal,\n","                        sr=SR,\n","                        n_fft=2048*2,\n","                        hop_length=512,\n","                        win_length=1024,\n","                        n_mels=n_mels  # Change n_mels here\n","                    )\n","                    mean_of_mel = np.mean(segment_mel_spec, axis=-1)\n","\n","                    mel_spec_data.append(mean_of_mel)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","\n","    # audio_data = tf.keras.preprocessing.sequence.pad_sequences(audio_data)\n","    mel_spec_data = tf.keras.preprocessing.sequence.pad_sequences(mel_spec_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","    # mean_audio = np.mean(audio_data)\n","    # std_audio = np.std(audio_data)\n","    # normalized_audio_data = (audio_data - mean_audio) / std_audio\n","\n","    mean_mel_spec = np.mean(mel_spec_data)\n","    std_mel_spec = np.std(mel_spec_data)\n","    normalized_mel_spec_data = (mel_spec_data - mean_mel_spec) / std_mel_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples)\n","\n","    return normalized_mel_spec_data, labels\n","\n"],"metadata":{"id":"puoZqMNHMzuZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_mels_values = [64, 128, 256]  # Modify the values as desired\n","\n","for n_mels in n_mels_values:\n","    mel_data, labels = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000, n_mels)\n","\n","    # Convert one-hot encoded labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(mel_data, y_labels, test_size=0.2, random_state=42)\n","\n","    print(\"n_mels:\", n_mels)\n","\n","    model_names = ['SVM', 'Random Forest', 'Naive Bayes', 'Decision Trees', 'k-Nearest Neighbors']\n","    for model_name in model_names:\n","        train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)\n","\n","    print(\"--------------------------------\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5MXO8g4pM49f","executionInfo":{"status":"ok","timestamp":1687878471960,"user_tz":-330,"elapsed":1981939,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"10031d81-f81c-4377-e412-d7a11010b12c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470\n","n_mels: 64\n","Model: SVM\n","Accuracy: 0.7884945621064682\n","Precision: 0.7888066424383442\n","Recall: 0.7884945621064682\n","F1 Score: 0.7884099712748027\n","Confusion Matrix:\n","[[2675  800]\n"," [ 678 2835]]\n","\n","\n","Model: Random Forest\n","Accuracy: 0.9281625643961076\n","Precision: 0.9281689564691489\n","Recall: 0.9281625643961076\n","F1 Score: 0.9281630233886554\n","Confusion Matrix:\n","[[3230  245]\n"," [ 257 3256]]\n","\n","\n","Model: Naive Bayes\n","Accuracy: 0.6788780767029193\n","Precision: 0.6877911321833616\n","Recall: 0.6788780767029193\n","F1 Score: 0.6753688022186978\n","Confusion Matrix:\n","[[2726  749]\n"," [1495 2018]]\n","\n","\n","Model: Decision Trees\n","Accuracy: 0.9022610188895249\n","Precision: 0.902457824785463\n","Recall: 0.9022610188895249\n","F1 Score: 0.9022554644891988\n","Confusion Matrix:\n","[[3171  304]\n"," [ 379 3134]]\n","\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.8918145392100744\n","Precision: 0.8919567991075075\n","Recall: 0.8918145392100744\n","F1 Score: 0.8918108526404477\n","Confusion Matrix:\n","[[3129  346]\n"," [ 410 3103]]\n","\n","\n","--------------------------------\n","\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","n_mels: 128\n","Model: SVM\n","Accuracy: 0.7844876931883228\n","Precision: 0.7847235900992631\n","Recall: 0.7844876931883228\n","F1 Score: 0.7844180734298993\n","Confusion Matrix:\n","[[2668  807]\n"," [ 699 2814]]\n","\n","\n","Model: Random Forest\n","Accuracy: 0.9447624499141385\n","Precision: 0.9447687277676625\n","Recall: 0.9447624499141385\n","F1 Score: 0.9447628028446633\n","Confusion Matrix:\n","[[3288  187]\n"," [ 199 3314]]\n","\n","\n","Model: Naive Bayes\n","Accuracy: 0.6528334287349743\n","Precision: 0.7757073604698721\n","Recall: 0.6528334287349743\n","F1 Score: 0.6082631627048651\n","Confusion Matrix:\n","[[1094 2381]\n"," [  45 3468]]\n","\n","\n","Model: Decision Trees\n","Accuracy: 0.9208643388666286\n","Precision: 0.9208889644933347\n","Recall: 0.9208643388666286\n","F1 Score: 0.9208648655520608\n","Confusion Matrix:\n","[[3211  264]\n"," [ 289 3224]]\n","\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.8941041785918717\n","Precision: 0.8941203877593237\n","Recall: 0.8941041785918717\n","F1 Score: 0.8941049592815064\n","Confusion Matrix:\n","[[3115  360]\n"," [ 380 3133]]\n","\n","\n","--------------------------------\n","\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","n_mels: 256\n","Model: SVM\n","Accuracy: 0.7932169433314253\n","Precision: 0.7970047987482514\n","Recall: 0.7932169433314253\n","F1 Score: 0.792468540487237\n","Confusion Matrix:\n","[[2552  923]\n"," [ 522 2991]]\n","\n","\n","Model: Random Forest\n","Accuracy: 0.9569261591299371\n","Precision: 0.9569475006092792\n","Recall: 0.9569261591299371\n","F1 Score: 0.9569264634488212\n","Confusion Matrix:\n","[[3336  139]\n"," [ 162 3351]]\n","\n","\n","Model: Naive Bayes\n","Accuracy: 0.6515455065827133\n","Precision: 0.779463569832968\n","Recall: 0.6515455065827133\n","F1 Score: 0.6054662749876111\n","Confusion Matrix:\n","[[1074 2401]\n"," [  34 3479]]\n","\n","\n","Model: Decision Trees\n","Accuracy: 0.9273039496279336\n","Precision: 0.9274935890235615\n","Recall: 0.9273039496279336\n","F1 Score: 0.9273003052222273\n","Confusion Matrix:\n","[[3257  218]\n"," [ 290 3223]]\n","\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.8933886662850601\n","Precision: 0.8935535661222065\n","Recall: 0.8933886662850601\n","F1 Score: 0.8933839962846871\n","Confusion Matrix:\n","[[3137  338]\n"," [ 407 3106]]\n","\n","\n","--------------------------------\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jWsCry546P4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N3vG-2yUuxe3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mfcc"],"metadata":{"id":"ukL5T9GH8DZG"}},{"cell_type":"code","source":["def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit, n_mfcc):\n","    audio_data = []\n","    mfcc_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=1747)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    audio_data.append(adjusted_audio_signal)\n","\n","                    mfcc = librosa.feature.mfcc(y=adjusted_audio_signal, sr=SR, n_mfcc=n_mfcc, n_fft=1024, hop_length=512)\n","                    mean_mfcc = np.mean(mfcc, axis=-1)\n","\n","                    mfcc_data.append(mean_mfcc)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","\n","    # audio_data = tf.keras.preprocessing.sequence.pad_sequences(audio_data)\n","    mfcc_data = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","    # mean_audio = np.mean(audio_data)\n","    # std_audio = np.std(audio_data)\n","    # normalized_audio_data = (audio_data - mean_audio) / std_audio\n","\n","    mean_mfcc = np.mean(mfcc_data)\n","    std_mfcc = np.std(mfcc_data)\n","    normalized_mfcc_data = (mfcc_data - mean_mfcc) / std_mfcc\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples)\n","\n","    return normalized_mfcc_data, labels\n","\n"],"metadata":{"id":"uecn4vQnJuQZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_mfcc_values = [13, 23, 33]  # Modify the values as desired\n","model_names = ['SVM', 'Random Forest', 'Naive Bayes', 'Decision Trees', 'k-Nearest Neighbors']\n","\n","for model_name in model_names:\n","    for n_mfcc in n_mfcc_values:\n","        mfcc_data, labels_mfcc = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000, n_mfcc)\n","\n","        # Convert one-hot encoded labels to 1D array\n","        y_labels = np.argmax(labels_mfcc, axis=1)\n","\n","        # Split the data into training and testing sets\n","        X_train, X_test, y_train, y_test = train_test_split(mfcc_data, y_labels, test_size=0.2, random_state=42)\n","\n","        train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)\n","\n","        print(\"n_mfcc:\", n_mfcc)\n","        print(\"Model:\", model_name)\n","        print(\"-------------------------------------\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QgqKNBKHt548","executionInfo":{"status":"ok","timestamp":1687882586298,"user_tz":-330,"elapsed":3791045,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"017f61ea-3d65-44fb-8ad5-fdd1ae560c6a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: SVM\n","Accuracy: 0.9895535203205496\n","Precision: 0.9897018218416869\n","Recall: 0.9895535203205496\n","F1 Score: 0.9895522281603026\n","Confusion Matrix:\n","[[3408   67]\n"," [   6 3507]]\n","\n","\n","n_mfcc: 13\n","Model: SVM\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: SVM\n","Accuracy: 0.9937034917000572\n","Precision: 0.9937499188326328\n","Recall: 0.9937034917000572\n","F1 Score: 0.9937031760168299\n","Confusion Matrix:\n","[[3436   39]\n"," [   5 3508]]\n","\n","\n","n_mfcc: 23\n","Model: SVM\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: SVM\n","Accuracy: 0.9935603892386949\n","Precision: 0.9936215079316395\n","Recall: 0.9935603892386949\n","F1 Score: 0.9935599931778675\n","Confusion Matrix:\n","[[3433   42]\n"," [   3 3510]]\n","\n","\n","n_mfcc: 33\n","Model: SVM\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Random Forest\n","Accuracy: 0.995277618775043\n","Precision: 0.9953027951524815\n","Recall: 0.995277618775043\n","F1 Score: 0.9952774664500702\n","Confusion Matrix:\n","[[3446   29]\n"," [   4 3509]]\n","\n","\n","n_mfcc: 13\n","Model: Random Forest\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Random Forest\n","Accuracy: 0.9974241556954779\n","Precision: 0.9974320864221315\n","Recall: 0.9974241556954779\n","F1 Score: 0.9974241172921162\n","Confusion Matrix:\n","[[3459   16]\n"," [   2 3511]]\n","\n","\n","n_mfcc: 23\n","Model: Random Forest\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Random Forest\n","Accuracy: 0.9974241556954779\n","Precision: 0.9974299754177225\n","Recall: 0.9974241556954779\n","F1 Score: 0.9974241240444879\n","Confusion Matrix:\n","[[3460   15]\n"," [   3 3510]]\n","\n","\n","n_mfcc: 33\n","Model: Random Forest\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Naive Bayes\n","Accuracy: 0.887378362907842\n","Precision: 0.890021018732874\n","Recall: 0.887378362907842\n","F1 Score: 0.8872158077377993\n","Confusion Matrix:\n","[[3224  251]\n"," [ 536 2977]]\n","\n","\n","n_mfcc: 13\n","Model: Naive Bayes\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Naive Bayes\n","Accuracy: 0.9338866628506011\n","Precision: 0.9341783104170643\n","Recall: 0.9338866628506011\n","F1 Score: 0.9338704647237964\n","Confusion Matrix:\n","[[3198  277]\n"," [ 185 3328]]\n","\n","\n","n_mfcc: 23\n","Model: Naive Bayes\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Naive Bayes\n","Accuracy: 0.9401831711505438\n","Precision: 0.9403368435938109\n","Recall: 0.9401831711505438\n","F1 Score: 0.9401811328091364\n","Confusion Matrix:\n","[[3298  177]\n"," [ 241 3272]]\n","\n","\n","n_mfcc: 33\n","Model: Naive Bayes\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Decision Trees\n","Accuracy: 0.9852604464796795\n","Precision: 0.9852638726575211\n","Recall: 0.9852604464796795\n","F1 Score: 0.9852605252615926\n","Confusion Matrix:\n","[[3428   47]\n"," [  56 3457]]\n","\n","\n","n_mfcc: 13\n","Model: Decision Trees\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Decision Trees\n","Accuracy: 0.9871207784773898\n","Precision: 0.9871234925666913\n","Recall: 0.9871207784773898\n","F1 Score: 0.9871208417772961\n","Confusion Matrix:\n","[[3434   41]\n"," [  49 3464]]\n","\n","\n","n_mfcc: 23\n","Model: Decision Trees\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: Decision Trees\n","Accuracy: 0.9886949055523755\n","Precision: 0.9886995560550677\n","Recall: 0.9886949055523755\n","F1 Score: 0.9886947807627383\n","Confusion Matrix:\n","[[3430   45]\n"," [  34 3479]]\n","\n","\n","n_mfcc: 33\n","Model: Decision Trees\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: k-Nearest Neighbors\n","Accuracy: 0.9919862621637092\n","Precision: 0.9920131852859916\n","Recall: 0.9919862621637092\n","F1 Score: 0.9919859890653506\n","Confusion Matrix:\n","[[3434   41]\n"," [  15 3498]]\n","\n","\n","n_mfcc: 13\n","Model: k-Nearest Neighbors\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: k-Nearest Neighbors\n","Accuracy: 0.9958500286204923\n","Precision: 0.9958590713500511\n","Recall: 0.9958500286204923\n","F1 Score: 0.9958499610539927\n","Confusion Matrix:\n","[[3453   22]\n"," [   7 3506]]\n","\n","\n","n_mfcc: 23\n","Model: k-Nearest Neighbors\n","-------------------------------------\n","Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: k-Nearest Neighbors\n","Accuracy: 0.9964224384659416\n","Precision: 0.99643409682291\n","Recall: 0.9964224384659416\n","F1 Score: 0.9964223699613258\n","Confusion Matrix:\n","[[3454   21]\n"," [   4 3509]]\n","\n","\n","n_mfcc: 33\n","Model: k-Nearest Neighbors\n","-------------------------------------\n"]}]},{"cell_type":"markdown","source":["# Zcr"],"metadata":{"id":"SDhK-NfBwYtF"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    audio_data = []\n","    feature_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=1747)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    audio_data.append(adjusted_audio_signal)\n","\n","                    zcr = librosa.feature.zero_crossing_rate(y=adjusted_audio_signal, frame_length=2048, hop_length=512)\n","                    mean_zcr = np.mean(zcr, axis=-1)\n","\n","                    feature_data.append(mean_zcr)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","\n","    # audio_data = np.array(audio_data)\n","    feature_data = np.array(feature_data)\n","    labels = np.array(labels)\n","\n","    imputer = SimpleImputer(strategy='mean')\n","    feature_data = imputer.fit_transform(feature_data)\n","\n","    scaler = StandardScaler()\n","    normalized_feature_data = scaler.fit_transform(feature_data)\n","\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples)\n","\n","    return normalized_feature_data, labels\n","\n","\n","\n","model_names = ['SVM', 'Random Forest', 'Naive Bayes', 'Decision Trees', 'k-Nearest Neighbors']\n","zcr_data, labels_zcr = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n","\n","y_labels = np.argmax(labels_zcr, axis=1)\n","\n","X_train, X_test, y_train, y_test = train_test_split(zcr_data, y_labels, test_size=0.2, random_state=42)\n","\n","for model_name in model_names:\n","    train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)\n","    print(\"Model:\", model_name)\n","    print(\"-------------------------------------\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8h7xbQJDsq5c","executionInfo":{"status":"ok","timestamp":1687887197901,"user_tz":-330,"elapsed":114498,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"b6f7a007-9350-4e64-fa1f-001893387322"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: SVM\n","Accuracy: 0.6040354894104178\n","Precision: 0.6083105619406373\n","Recall: 0.6040354894104178\n","F1 Score: 0.6006695550766448\n","Confusion Matrix:\n","[[2422 1053]\n"," [1714 1799]]\n","\n","\n","Model: SVM\n","-------------------------------------\n","Model: Random Forest\n","Accuracy: 0.5487979393245563\n","Precision: 0.5487958685296906\n","Recall: 0.5487979393245564\n","F1 Score: 0.5487968027829376\n","Confusion Matrix:\n","[[1897 1578]\n"," [1575 1938]]\n","\n","\n","Model: Random Forest\n","-------------------------------------\n","Model: Naive Bayes\n","Accuracy: 0.5941614195764167\n","Precision: 0.5941830560164263\n","Recall: 0.5941614195764167\n","F1 Score: 0.5941640125817634\n","Confusion Matrix:\n","[[2070 1405]\n"," [1431 2082]]\n","\n","\n","Model: Naive Bayes\n","-------------------------------------\n","Model: Decision Trees\n","Accuracy: 0.5429307384087007\n","Precision: 0.5439157368682802\n","Recall: 0.5429307384087007\n","F1 Score: 0.5413169074433679\n","Confusion Matrix:\n","[[2095 1380]\n"," [1814 1699]]\n","\n","\n","Model: Decision Trees\n","-------------------------------------\n","Model: k-Nearest Neighbors\n","Accuracy: 0.5712650257584431\n","Precision: 0.5713793817190477\n","Recall: 0.5712650257584431\n","F1 Score: 0.57121880608295\n","Confusion Matrix:\n","[[2024 1451]\n"," [1545 1968]]\n","\n","\n","Model: k-Nearest Neighbors\n","-------------------------------------\n"]}]},{"cell_type":"markdown","source":["# psd"],"metadata":{"id":"-CMu8fdN1axG"}},{"cell_type":"code","source":["# def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","#     audio_data = []\n","#     feature_data = []\n","#     labels = []\n","\n","#     segment_sr_required = duration * SR\n","\n","#     no_of_drone_samples = 0\n","#     no_of_swarm_drone_samples = 0\n","\n","#     for file_name in os.listdir(main_folder_path):\n","#         if 'drone'.lower() in file_name.lower():\n","#             flag = 0\n","#         elif 'swarm'.lower() in file_name.lower():\n","#             flag = 1\n","#         else:\n","#             continue\n","\n","#         if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","#             file_path = os.path.join(main_folder_path, file_name)\n","#             signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","#             signal_data = signal_data / np.max(np.abs(signal_data))\n","#             noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=1747)\n","#             noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","#             s = len(signal_data)\n","#             n = len(noise_data)\n","\n","#             if n > s:\n","#                 noise_data = noise_data[0:s]\n","#             elif s > n:\n","#                 w = s - n\n","#                 noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","#             else:\n","#                 pass\n","\n","#             N = int(len(signal_data) / segment_sr_required)\n","\n","#             for i in range(N):\n","#                 start = i * segment_sr_required\n","#                 end = start + segment_sr_required\n","\n","#                 if end - start != SR:\n","#                     continue\n","\n","#                 segment = signal_data[start:end]\n","#                 start_noise = np.random.randint(0, N-1) * segment_sr_required\n","#                 end_noise = start_noise + segment_sr_required\n","\n","#                 if end_noise - start_noise != SR:\n","#                     continue\n","\n","#                 noise = noise_data[start_noise:end_noise]\n","\n","#                 rms_signal = np.mean(np.square(segment))\n","#                 rms_noise = np.mean(np.square(noise))\n","\n","#                 dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","#                 for j in range(len(dbset)):\n","#                     rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","#                     scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","#                     adjusted_audio_signal = segment * scaling_factor\n","\n","#                     adjusted_audio_signal += noise\n","\n","#                     audio_data.append(adjusted_audio_signal)\n","\n","#                     psd = np.abs(np.fft.fft(adjusted_audio_signal)) ** 2\n","#                     mean_psd = np.mean(psd, axis=-1)\n","\n","#                     feature_data.append(mean_psd)\n","#                     labels.append(flag)\n","\n","#                     if flag == 0:\n","#                         no_of_drone_samples += 1\n","#                     elif flag == 1:\n","#                         no_of_swarm_drone_samples += 1\n","\n","#     # audio_data = np.array(audio_data)\n","#     feature_data = np.array(feature_data)\n","#     labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","#     mean_feature = np.mean(feature_data)\n","#     std_feature = np.std(feature_data)\n","#     normalized_feature_data = (feature_data - mean_feature) / std_feature\n","\n","#     print(\"Drone samples:\", no_of_drone_samples,\n","#           \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples)\n","\n","#     return normalized_feature_data, labels\n","\n","# feature_data, labels = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n","\n","# # Convert one-hot encoded labels to 1D array\n","# y_labels = np.argmax(labels, axis=1)\n","\n","# feature_data = feature_data.reshape(-1, 1)\n","\n","# # Split the data into training and testing sets\n","# X_train, X_test, y_train, y_test = train_test_split(feature_data, y_labels, test_size=0.2, random_state=42)\n","\n","# for model_name in model_names:\n","#     train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)\n","\n","#     print(\"Model:\", model_name)\n","#     print(\"-------------------------------------\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XlI0z2dvAwN","executionInfo":{"status":"ok","timestamp":1687886031676,"user_tz":-330,"elapsed":121959,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"7b905515-4c4f-45ef-a991-9a71f6441a09"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: SVM\n","Accuracy: 0.4935603892386949\n","Precision: 0.49363403634986014\n","Recall: 0.4935603892386949\n","F1 Score: 0.4726617873308482\n","Confusion Matrix:\n","[[2411 1064]\n"," [2475 1038]]\n","\n","\n","Model: SVM\n","-------------------------------------\n","Model: Random Forest\n","Accuracy: 0.4951345163136806\n","Precision: 0.4951297872337345\n","Recall: 0.4951345163136806\n","F1 Score: 0.4951317867638148\n","Confusion Matrix:\n","[[1708 1767]\n"," [1761 1752]]\n","\n","\n","Model: Random Forest\n","-------------------------------------\n","Model: Naive Bayes\n","Accuracy: 0.4975672581568403\n","Precision: 0.4990371704690984\n","Recall: 0.4975672581568403\n","F1 Score: 0.42181099873051714\n","Confusion Matrix:\n","[[2995  480]\n"," [3031  482]]\n","\n","\n","Model: Naive Bayes\n","-------------------------------------\n","Model: Decision Trees\n","Accuracy: 0.49527761877504295\n","Precision: 0.4952985460810406\n","Recall: 0.49527761877504295\n","F1 Score: 0.495280688534148\n","Confusion Matrix:\n","[[1725 1750]\n"," [1777 1736]]\n","\n","\n","Model: Decision Trees\n","-------------------------------------\n","Model: k-Nearest Neighbors\n","Accuracy: 0.4948483113909559\n","Precision: 0.4948924965560391\n","Recall: 0.4948483113909559\n","F1 Score: 0.4948363114927179\n","Confusion Matrix:\n","[[1739 1736]\n"," [1794 1719]]\n","\n","\n","Model: k-Nearest Neighbors\n","-------------------------------------\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","def train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name):\n","    if model_name == 'SVM':\n","        model = SVC()\n","    elif model_name == 'Random Forest':\n","        model = RandomForestClassifier()\n","    elif model_name == 'Naive Bayes':\n","        model = GaussianNB()\n","    elif model_name == 'Decision Trees':\n","        model = DecisionTreeClassifier()\n","    elif model_name == 'k-Nearest Neighbors':\n","        model = KNeighborsClassifier()\n","\n","    model.fit(X_train, y_train)\n","\n","    train_score = model.score(X_train, y_train)\n","    test_score = model.score(X_test, y_test)\n","\n","    print(\"Training Accuracy (\" + model_name + \"):\", train_score)\n","    print(\"Testing Accuracy (\" + model_name + \"):\", test_score)\n","    print(\"-------------------------------------\")\n","\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    audio_data = []\n","    feature_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=1747)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    audio_data.append(adjusted_audio_signal)\n","\n","                    psd = np.abs(np.fft.fft(adjusted_audio_signal)) ** 2\n","                    mean_psd = np.mean(psd, axis=-1)\n","\n","                    feature_data.append(mean_psd)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","\n","    audio_data = np.array(audio_data)\n","    feature_data = np.array(feature_data)\n","    labels = np.array(labels)\n","\n","    mean_feature = np.mean(feature_data)\n","    std_feature = np.std(feature_data)\n","    normalized_feature_data = (feature_data - mean_feature) / std_feature\n","\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples)\n","\n","    return normalized_feature_data, labels\n","\n","model_names = ['SVM', 'Random Forest', 'Naive Bayes', 'Decision Trees', 'k-Nearest Neighbors']\n","zcr_data, labels_zcr = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n","\n","y_labels = np.argmax(labels_zcr, axis=1)\n","\n","zcr_data = zcr_data.reshape(-1, 1)\n","\n","X_train, X_test, y_train, y_test = train_test_split(zcr_data, y_labels, test_size=0.2, random_state=42)\n","\n","for model_name in model_names:\n","    train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)\n","    print(\"Model:\", model_name)\n","    print(\"-------------------------------------\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gcbfev2H1Uc4","executionInfo":{"status":"ok","timestamp":1687887645333,"user_tz":-330,"elapsed":163544,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"bb5496e4-b893-4687-b865-337273c6e26f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Training Accuracy (SVM): 0.5031124785346308\n","Testing Accuracy (SVM): 0.49985689753863766\n","-------------------------------------\n","Model: SVM\n","-------------------------------------\n","Training Accuracy (Random Forest): 0.9896608471665712\n","Testing Accuracy (Random Forest): 0.4985689753863766\n","-------------------------------------\n","Model: Random Forest\n","-------------------------------------\n","Training Accuracy (Naive Bayes): 0.5003219805380652\n","Testing Accuracy (Naive Bayes): 0.5065827132226675\n","-------------------------------------\n","Model: Naive Bayes\n","-------------------------------------\n","Training Accuracy (Decision Trees): 0.9900186033199772\n","Testing Accuracy (Decision Trees): 0.49899828277046365\n","-------------------------------------\n","Model: Decision Trees\n","-------------------------------------\n","Training Accuracy (k-Nearest Neighbors): 0.6898254149971379\n","Testing Accuracy (k-Nearest Neighbors): 0.4886949055523755\n","-------------------------------------\n","Model: k-Nearest Neighbors\n","-------------------------------------\n"]}]},{"cell_type":"markdown","source":["# Spectral centroid"],"metadata":{"id":"y5riTAtW34oP"}},{"cell_type":"code","source":["def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    audio_data = []\n","    spectral_centroid_data = []\n","    labels = []\n","    duration = 1\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=1747)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    audio_data.append(adjusted_audio_signal)\n","\n","                    spectral_centroid = librosa.feature.spectral_centroid(\n","                        y=adjusted_audio_signal,\n","                        sr=SR,\n","                        n_fft=2048*2,\n","                        hop_length=512,\n","                        win_length=1024\n","                    )\n","                    mean_of_spectral_centroid = np.mean(spectral_centroid)\n","\n","                    spectral_centroid_data.append(mean_of_spectral_centroid)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","\n","    # audio_data = tf.keras.preprocessing.sequence.pad_sequences(audio_data)\n","    spectral_centroid_data = np.array(spectral_centroid_data).reshape(-1, 1)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","    # mean_audio = np.mean(audio_data)\n","    # std_audio = np.std(audio_data)\n","    # normalized_audio_data = (audio_data - mean_audio) / std_audio\n","\n","    mean_spectral_centroid = np.mean(spectral_centroid_data)\n","    std_spectral_centroid = np.std(spectral_centroid_data)\n","    normalized_spectral_centroid_data = (spectral_centroid_data - mean_spectral_centroid) / std_spectral_centroid\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples)\n","\n","    return normalized_spectral_centroid_data, labels\n","\n"],"metadata":{"id":"gSzSjvir38of"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spectral_centroid_data, labels = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n","\n","# Convert one-hot encoded labels to 1D array\n","y_labels = np.argmax(labels, axis=1)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(spectral_centroid_data, y_labels, test_size=0.2, random_state=42)\n","\n","for model_name in model_names:\n","\n","    train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)\n","\n","    # print(\"n_samples:\", n)\n","    print(\"Model:\", model_name)\n","    print(\"-------------------------------------\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1djHLnYx4k0D","executionInfo":{"status":"ok","timestamp":1687886378845,"user_tz":-330,"elapsed":331289,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"6aa7e8c7-9821-4c95-dd4d-c2cea08dff43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470\n","Model: SVM\n","Accuracy: 0.7228105323411562\n","Precision: 0.7343285669575679\n","Recall: 0.7228105323411562\n","F1 Score: 0.7190917008696133\n","Confusion Matrix:\n","[[2114 1361]\n"," [ 576 2937]]\n","\n","\n","Model: SVM\n","-------------------------------------\n","Model: Random Forest\n","Accuracy: 0.6315111619919863\n","Precision: 0.6315095383852788\n","Recall: 0.6315111619919863\n","F1 Score: 0.6315102337983077\n","Confusion Matrix:\n","[[2186 1289]\n"," [1286 2227]]\n","\n","\n","Model: Random Forest\n","-------------------------------------\n","Model: Naive Bayes\n","Accuracy: 0.703062392673154\n","Precision: 0.7038183420464956\n","Recall: 0.703062392673154\n","F1 Score: 0.7026960764547798\n","Confusion Matrix:\n","[[2324 1151]\n"," [ 924 2589]]\n","\n","\n","Model: Naive Bayes\n","-------------------------------------\n","Model: Decision Trees\n","Accuracy: 0.6306525472238123\n","Precision: 0.6306519830728942\n","Recall: 0.6306525472238123\n","F1 Score: 0.6306522522337061\n","Confusion Matrix:\n","[[2184 1291]\n"," [1290 2223]]\n","\n","\n","Model: Decision Trees\n","-------------------------------------\n","Model: k-Nearest Neighbors\n","Accuracy: 0.6810246136233543\n","Precision: 0.681312907523823\n","Recall: 0.6810246136233543\n","F1 Score: 0.6808244782042904\n","Confusion Matrix:\n","[[2282 1193]\n"," [1036 2477]]\n","\n","\n","Model: k-Nearest Neighbors\n","-------------------------------------\n"]}]}]}