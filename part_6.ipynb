{"cells":[{"cell_type":"markdown","metadata":{"id":"4cbgwZWWfWpp"},"source":["# GLobal Code"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24149,"status":"ok","timestamp":1692450524963,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"CKvfi9jrpyhW","outputId":"85b27398-e489-47b5-bf52-fedc09a4fc1a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snkZZ8rKF3sH"},"outputs":[],"source":["pip install librosa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FT4WctOuxHCT"},"outputs":[],"source":["import os\n","import librosa\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import adjusted_rand_score\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import silhouette_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import tensorflow as tf\n","import librosa as lr\n","import soundfile as sf\n","import scipy.signal as sig\n","from random import random, randint, shuffle\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAb77yZ9fzMG"},"outputs":[],"source":["# pip install librosa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pafL7Li0jyXW"},"outputs":[],"source":["# import os\n","# import numpy as np\n","# import librosa\n","# import tensorflow as tf\n","\n","# def mix_audio(main_folder_path, duration, SR, Limit):\n","#     mel_spec_data = []\n","#     labels = []\n","\n","#     segment_sr_required = duration * SR\n","\n","#     no_of_drone_samples = 0\n","#     no_of_noise_samples = 0\n","\n","#     for file_name in os.listdir(main_folder_path):\n","#         if 'noise'.lower() in file_name.lower():\n","#             flag = 0\n","#         elif 'drone'.lower() in file_name.lower():\n","#             flag = 1\n","#         else:\n","#             continue\n","\n","#         if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","#             file_path = os.path.join(main_folder_path, file_name)\n","#             signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","#             signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","\n","#             N = int(len(signal_data) / segment_sr_required)\n","\n","#             for i in range(N):\n","#                 start = i * segment_sr_required\n","#                 end = start + segment_sr_required\n","\n","#                 if end - start != SR:\n","#                     continue\n","\n","#                 segment = signal_data[start:end]\n","\n","\n","#                 segment_mel_spec = librosa.feature.melspectrogram(y=segment, sr=SR, n_fft=2048, hop_length=512, win_length=1024, n_mels=256)\n","#                 mean_of_mel = np.mean(segment_mel_spec, axis=-1)\n","\n","#                 mel_spec_data.append(mean_of_mel)\n","#                 labels.append(flag)\n","\n","#                 if flag == 1:\n","#                     no_of_drone_samples += 1\n","#                 elif flag == 0:\n","#                     no_of_noise_samples += 1\n","\n","#     mel_spec_data = tf.keras.preprocessing.sequence.pad_sequences(mel_spec_data)\n","#     labels = tf.keras.utils.to_categorical(labels, num_classes=2)\n","\n","\n","#     mean_mel_spec = np.mean(mel_spec_data)\n","#     std_mel_spec = np.std(mel_spec_data)\n","#     normalized_mel_spec_data = (mel_spec_data - mean_mel_spec) / std_mel_spec\n","\n","#     print(\"Drone samples:\", no_of_drone_samples, \" Noise samples:\", no_of_noise_samples)\n","\n","#     return normalized_mel_spec_data, labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UMRzPgkTy7CS"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"nOlPD6f9y7Oh"},"source":["# Mel Binary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9RQFF2KyI5r"},"outputs":[],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    mel_spec_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                segment_mel_spec = librosa.feature.melspectrogram(\n","                    y=segment, sr=SR, n_fft=2048, hop_length=512, win_length=1024, n_mels=256\n","                )\n","                mean_of_mel = np.mean(segment_mel_spec, axis=-1)\n","\n","                mel_spec_data.append(mean_of_mel)\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    mel_spec_data = tf.keras.preprocessing.sequence.pad_sequences(mel_spec_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    mean_mel_spec = np.mean(mel_spec_data)\n","    std_mel_spec = np.std(mel_spec_data)\n","    normalized_mel_spec_data = (mel_spec_data - mean_mel_spec) / std_mel_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_mel_spec_data, labels\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":481034,"status":"ok","timestamp":1690464831850,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"D7JPt_w-ybQC","outputId":"83d3e0ce-48d4-47d9-d226-d67518ffe26e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n"]}],"source":["# Specify the dataset directory, duration, sample rate (SR), and limit\n","dataset_dir = '/content/drive/MyDrive/new_mixed'\n","duration = 1\n","SR = 44100\n","Limit = 21000\n","\n","# Mix audio and extract mel spectrogram data with labels\n","mel_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    mel_data, labels, test_size=0.2, random_state=42\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ypb0l4AfydVD","executionInfo":{"status":"ok","timestamp":1690464921179,"user_tz":-330,"elapsed":89339,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"0b22b550-8b38-4103-cef3-3e01b6fbec88"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8206106870229007\n"]}],"source":["# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]},{"cell_type":"markdown","metadata":{"id":"JPnjPYQhK99I"},"source":["# MFCC\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rY8qskhy3gD"},"outputs":[],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    mfcc_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                segment_mfcc = librosa.feature.mfcc(\n","                    y=segment, sr=SR, n_mfcc=20\n","                )\n","                mean_of_mfcc = np.mean(segment_mfcc, axis=-1)\n","\n","                mfcc_data.append(mean_of_mfcc)\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    mfcc_data = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    mean_mfcc = np.mean(mfcc_data)\n","    std_mfcc = np.std(mfcc_data)\n","    normalized_mfcc_data = (mfcc_data - mean_mfcc) / std_mfcc\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_mfcc_data, labels\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":563429,"status":"ok","timestamp":1692451106682,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"WTHxWTNuzkZS","outputId":"c01d0c8d-614b-4089-d924-ab38be67fd15"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n"]}],"source":["# Specify the dataset directory, duration, sample rate (SR), and limit\n","dataset_dir = '/content/drive/MyDrive/new_mixed'\n","duration = 1\n","SR = 44100\n","Limit = 21000\n","\n","# Mix audio and extract MFCC data with labels\n","mfcc_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    mfcc_data, labels, test_size=0.2, random_state=42\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8019,"status":"ok","timestamp":1692451116088,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"g-CTUWOxznHk","outputId":"e93d372a-d05e-4e56-a5a1-b5cdd4e1caff"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9514949109414759\n"]}],"source":["# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n"]},{"cell_type":"code","source":["from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_NbxNmjk6fM-","executionInfo":{"status":"ok","timestamp":1692451116768,"user_tz":-330,"elapsed":711,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"7c9f8fc1-cf29-4270-da52-430ec806a701"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Confusion Matrix:\n"," [[2973  125]\n"," [ 180 3010]]\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.94      0.96      0.95      3098\n","           1       0.96      0.94      0.95      3190\n","\n","    accuracy                           0.95      6288\n","   macro avg       0.95      0.95      0.95      6288\n","weighted avg       0.95      0.95      0.95      6288\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"oXq6l_9b1kwy"},"source":["# PSD log base 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rykEunKC1oKS"},"outputs":[],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from scipy import signal\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    psd_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                f, psd = signal.welch(segment, SR)\n","                log_psd = np.log10(psd)\n","\n","                psd_data.append(log_psd)\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    psd_data = tf.keras.preprocessing.sequence.pad_sequences(psd_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    mean_psd = np.mean(psd_data)\n","    std_psd = np.std(psd_data)\n","    normalized_psd_data = (psd_data - mean_psd) / std_psd\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_psd_data, labels\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":58484,"status":"ok","timestamp":1690465345562,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"l0-c79Bk13UC","outputId":"afee33ad-3589-46d5-8945-a92fc507b1fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n"]}],"source":["# Specify the dataset directory, duration, sample rate (SR), and limit\n","dataset_dir = '/content/drive/MyDrive/new_mixed'\n","duration = 1\n","SR = 44100\n","Limit = 21000\n","\n","# Mix audio and extract PSD data with labels\n","psd_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55347,"status":"ok","timestamp":1690465400857,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"BqXhMFmM1_qi","outputId":"4a01506c-d865-4ba5-992f-0c59269df10a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8489185750636132\n"]}],"source":["# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    psd_data, labels, test_size=0.2, random_state=48\n",")\n","\n","# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]},{"cell_type":"markdown","metadata":{"id":"SsKQEwfJ3JYy"},"source":["# psd(without log)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":116444,"status":"ok","timestamp":1690465517249,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"efonXlka3MOJ","outputId":"0e20292c-13b5-46f4-b726-d35ed6608509"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n","Accuracy: 0.49268447837150126\n"]}],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from scipy import signal\n","from sklearn.preprocessing import RobustScaler\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    psd_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                f, psd = signal.welch(segment, SR)\n","\n","                psd_data.append(psd)\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    if len(psd_data) == 0:\n","        raise ValueError(\"No valid PSD data extracted from audio segments.\")\n","\n","    psd_data = tf.keras.preprocessing.sequence.pad_sequences(psd_data)\n","    psd_data[np.isnan(psd_data)] = 0  # Replace remaining NaN values with zero\n","\n","    if np.count_nonzero(psd_data) > 0:\n","        psd_data[psd_data == 0] = np.min(psd_data[psd_data != 0])  # Replace zero values with the minimum non-zero value\n","\n","    scaler = RobustScaler()\n","    normalized_psd_data = scaler.fit_transform(np.log1p(psd_data))  # Apply log1p transformation to handle zero and large values\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_psd_data, labels\n","\n","# Specify the dataset directory, duration, sample rate (SR), and limit\n","# dataset_dir = 'path_to_dataset_folder'\n","# duration = 1\n","# SR = 44100\n","# Limit = 21000\n","\n","# Mix audio and extract PSD data with labels\n","psd_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    psd_data, labels, test_size=0.2, random_state=42\n",")\n","\n","# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]},{"cell_type":"markdown","metadata":{"id":"JphPk3dC80JJ"},"source":["# Spectral centroid with log base 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":264298,"status":"ok","timestamp":1690465781539,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"g44rTAro9J1w","outputId":"84049c66-89c8-4eba-c17f-71252a9a6d33"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n","Accuracy: 0.5146310432569975\n"]}],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import RobustScaler\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    centroid_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                centroid = librosa.feature.spectral_centroid(y=segment, sr=SR)\n","                log_centroid = np.log10(centroid)\n","\n","                centroid_data.append(log_centroid)\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    centroid_data = tf.keras.preprocessing.sequence.pad_sequences(centroid_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    scaler = RobustScaler()\n","\n","    # Reshape centroid_data to 2D array\n","    num_segments, num_frames, num_features = centroid_data.shape\n","    centroid_data = centroid_data.reshape(num_segments * num_frames, num_features)\n","\n","    normalized_centroid_data = scaler.fit_transform(centroid_data)\n","\n","    # Reshape back to 3D array\n","    normalized_centroid_data = normalized_centroid_data.reshape(num_segments, num_frames, num_features)\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_centroid_data, labels\n","\n","# Specify the dataset directory, duration, sample rate (SR), and limit\n","dataset_dir = '/content/drive/MyDrive/new_mixed'\n","duration = 1\n","SR = 44100\n","Limit = 21000\n","\n","# Mix audio and extract spectral centroid data with labels\n","centroid_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    centroid_data, labels, test_size=0.2, random_state=48\n",")\n","\n","# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train.reshape(X_train.shape[0], -1), y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test.reshape(X_test.shape[0], -1))\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]},{"cell_type":"markdown","metadata":{"id":"bZsZ7t_L9F0R"},"source":["# Spectral centroid without log base 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":222244,"status":"ok","timestamp":1690466003774,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"x9L4emMV9JRJ","outputId":"217f81a2-7634-439b-97e5-923af816f8f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n","Accuracy: 0.5548664122137404\n"]}],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import RobustScaler\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    centroid_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                centroid = librosa.feature.spectral_centroid(y=segment, sr=sr)\n","\n","                centroid_data.append(centroid[0])  # Extract the centroid array from the 2D matrix\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    if len(centroid_data) == 0:\n","        raise ValueError(\"No valid centroid data extracted from audio segments.\")\n","\n","    centroid_data = tf.keras.preprocessing.sequence.pad_sequences(centroid_data)\n","    centroid_data[np.isnan(centroid_data)] = 0  # Replace remaining NaN values with zero\n","\n","    if np.count_nonzero(centroid_data) > 0:\n","        centroid_data[centroid_data == 0] = np.min(centroid_data[centroid_data != 0])  # Replace zero values with the minimum non-zero value\n","\n","    scaler = RobustScaler()\n","    normalized_centroid_data = scaler.fit_transform(np.log1p(centroid_data))  # Apply log1p transformation to handle zero and large values\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_centroid_data, labels\n","\n","# Specify the dataset directory, duration, sample rate (SR), and limit\n","# dataset_dir = 'path_to_dataset_folder'\n","# duration = 1\n","# SR = 44100\n","# Limit = 21000\n","\n","# Mix audio and extract centroid data with labels\n","centroid_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    centroid_data, labels, test_size=0.2, random_state=42\n",")\n","\n","# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o1PiETaB847v"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"sKl0gov3BiCf"},"source":["# zcr with log base 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":136545,"status":"ok","timestamp":1690466140315,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"1V-rwdV7BlDH","outputId":"9eae76e5-b227-4852-eb55-776fb3a069c5"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-7541280385d7>:44: RuntimeWarning: divide by zero encountered in log10\n","  log_zcr = np.log10(zcr)\n"]},{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n","Accuracy: 0.5812659033078881\n"]}],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import RobustScaler\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    zcr_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                zcr = librosa.feature.zero_crossing_rate(segment)\n","                log_zcr = np.log10(zcr)\n","\n","                zcr_data.append(log_zcr)\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    zcr_data = tf.keras.preprocessing.sequence.pad_sequences(zcr_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    scaler = RobustScaler()\n","\n","    # Reshape zcr_data to 2D array\n","    num_segments, _, num_frames = zcr_data.shape\n","    zcr_data = zcr_data.reshape(num_segments, num_frames)\n","\n","    normalized_zcr_data = scaler.fit_transform(zcr_data)\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_zcr_data, labels\n","\n","# Specify the dataset directory, duration, sample rate (SR), and limit\n","# dataset_dir = '/content/drive/MyDrive/iit_our_rec'\n","duration = 1\n","SR = 44100\n","Limit = 21000\n","\n","# Mix audio and extract ZCR data with labels\n","zcr_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    zcr_data, labels, test_size=0.2, random_state=48\n",")\n","\n","# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]},{"cell_type":"markdown","metadata":{"id":"X3dmi19jBZ0A"},"source":["# zcr w/o logbase10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":126293,"status":"ok","timestamp":1690466266576,"user":{"displayName":"grey matter","userId":"10604083454161431627"},"user_tz":-330},"id":"Klq0FGMXBbef","outputId":"dc71f0be-4415-457a-bb23-c94344efc04d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 15720 \n","Noise samples: 15720\n","Accuracy: 0.49268447837150126\n"]}],"source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import RobustScaler\n","\n","def mix_audio(main_folder_path, duration, SR, Limit):\n","    zcr_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_noise_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'noise'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'drone'.lower() in file_name.lower():\n","            flag = 1\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=15720)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","\n","                zcr = librosa.feature.zero_crossing_rate(segment)\n","\n","                zcr_data.append(zcr[0])  # Extract the ZCR array from the 2D matrix\n","                labels.append(flag)\n","\n","                if flag == 1:\n","                    no_of_drone_samples += 1\n","                elif flag == 0:\n","                    no_of_noise_samples += 1\n","\n","    if len(zcr_data) == 0:\n","        raise ValueError(\"No valid ZCR data extracted from audio segments.\")\n","\n","    zcr_data = tf.keras.preprocessing.sequence.pad_sequences(zcr_data)\n","    zcr_data[np.isnan(zcr_data)] = 0  # Replace remaining NaN values with zero\n","\n","    if np.count_nonzero(zcr_data) > 0:\n","        zcr_data[zcr_data == 0] = np.min(zcr_data[zcr_data != 0])  # Replace zero values with the minimum non-zero value\n","\n","    scaler = RobustScaler()\n","    normalized_zcr_data = scaler.fit_transform(zcr_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nNoise samples:\", no_of_noise_samples)\n","\n","    return normalized_zcr_data, labels\n","\n","# Specify the dataset directory, duration, sample rate (SR), and limit\n","dataset_dir = '/content/drive/MyDrive/new_mixed'\n","duration = 1\n","SR = 44100\n","Limit = 21000\n","\n","# Mix audio and extract ZCR data with labels\n","zcr_data, labels = mix_audio(dataset_dir, duration, SR, Limit)\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    zcr_data, labels, test_size=0.2, random_state=42\n",")\n","\n","# Create an SVM classifier\n","clf = svm.SVC(kernel='linear')\n","\n","# Train the SVM classifier\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = clf.predict(X_test)\n","\n","# Calculate the accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Print confusion matrix and classification report\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","class_report = classification_report(y_test, y_pred)\n","\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","print(\"\\nClassification Report:\\n\", class_report)\n"]}],"metadata":{"accelerator":"TPU","colab":{"machine_shape":"hm","provenance":[{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1689233611954},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}