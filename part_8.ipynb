{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1689413931411},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"machine_shape":"hm","collapsed_sections":["4cbgwZWWfWpp","PY11KUo07vMq","YnzQuVJ59VIx","brIGnYN5-Jhb","kyyRxAznJRQT"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4cbgwZWWfWpp"},"source":["# Global Code"]},{"cell_type":"code","source":["# pip install librosa"],"metadata":{"id":"HhJMNtqW7SK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"766xJ_e47nIM"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tAb77yZ9fzMG"},"source":["import os\n","import librosa\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import adjusted_rand_score\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import silhouette_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import tensorflow as tf\n","import librosa as lr\n","import soundfile as sf\n","import scipy.signal as sig\n","from random import random, randint, shuffle\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name):\n","    if model_name == 'SVM':\n","        model = SVC(C=10, kernel='rbf', gamma='scale')\n","    elif model_name == 'Random Forest':\n","        model = RandomForestClassifier(n_estimators=100, random_state=42)\n","    elif model_name == 'Naive Bayes':\n","        model = GaussianNB()\n","    elif model_name == 'Decision Trees':\n","        model = DecisionTreeClassifier(random_state=42)\n","    elif model_name == 'k-Nearest Neighbors':\n","        model = KNeighborsClassifier(n_neighbors=5)\n","\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","    confusion_mat = confusion_matrix(y_test, y_pred)\n","\n","    print(\"Model:\", model_name)\n","    print(\"Accuracy:\", accuracy)\n","    print(\"Precision:\", precision)\n","    print(\"Recall:\", recall)\n","    print(\"F1 Score:\", f1)\n","    print(\"Confusion Matrix:\")\n","    print(confusion_mat)\n","    print(\"--------------------------------\\n\")"],"metadata":{"id":"o-9RhLgT7Cfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_names = ['SVM', 'Random Forest', 'Naive Bayes', 'Decision Trees', 'k-Nearest Neighbors']\n"],"metadata":{"id":"zeZXXkWp7FXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pafL7Li0jyXW"},"source":["dataset_dir = '/content/drive/MyDrive/iit_our_rec/'\n","ambient_path = '/content/drive/MyDrive/iit_our_rec/noise_44min.wav'"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4PhFfc6R66AC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mel spectrogram"],"metadata":{"id":"PY11KUo07vMq"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    mel_spec_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    segment_mel_spec = librosa.feature.melspectrogram(y=adjusted_audio_signal, sr=SR, n_fft=2048, hop_length=512, win_length=1024, n_mels=256)\n","                    mean_of_mel = np.mean(segment_mel_spec, axis=-1)\n","\n","                    mel_spec_data.append(mean_of_mel)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    mel_spec_data = tf.keras.preprocessing.sequence.pad_sequences(mel_spec_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_mel_spec = np.mean(mel_spec_data)\n","    std_mel_spec = np.std(mel_spec_data)\n","    normalized_mel_spec_data = (mel_spec_data - mean_mel_spec) / std_mel_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples\n","          ,\"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_mel_spec_data, labels\n"],"metadata":{"id":"qfvAdR8m66Dp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mel_data, labels = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-nntX1BN8fdh","executionInfo":{"status":"ok","timestamp":1689415357696,"user_tz":-330,"elapsed":765400,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"ae6f0931-43ce-4c14-c4e3-838153f34b69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470 \n","Aircraft samples: 17470\n"]}]},{"cell_type":"code","source":["# Convert one-hot encoded labels to 1D array\n","y_labels = np.argmax(labels, axis=1)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(mel_data, y_labels, test_size=0.2, random_state=42)\n"],"metadata":{"id":"nVoFm5kU_Huf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_name in model_names:\n","  train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ssTvihkS_J3t","executionInfo":{"status":"ok","timestamp":1689416416333,"user_tz":-330,"elapsed":576462,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"e8399095-cf03-4405-804a-57f3c271b4f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: SVM\n","Accuracy: 0.5938752146536921\n","Precision: 0.7032562562438024\n","Recall: 0.5938752146536921\n","F1 Score: 0.5849125842324682\n","Confusion Matrix:\n","[[3136  221  113]\n"," [1654 1736   96]\n"," [1876  297 1353]]\n","--------------------------------\n","\n","Model: Random Forest\n","Accuracy: 0.8651974813966801\n","Precision: 0.8653506961271721\n","Recall: 0.8651974813966801\n","F1 Score: 0.8651417750740948\n","Confusion Matrix:\n","[[3020  186  264]\n"," [ 208 3090  188]\n"," [ 336  231 2959]]\n","--------------------------------\n","\n","Model: Naive Bayes\n","Accuracy: 0.45363480251860333\n","Precision: 0.7572200332682331\n","Recall: 0.45363480251860333\n","F1 Score: 0.388810736936837\n","Confusion Matrix:\n","[[ 789    2 2679]\n"," [   0  499 2987]\n"," [  16   43 3467]]\n","--------------------------------\n","\n","Model: Decision Trees\n","Accuracy: 0.808051898492654\n","Precision: 0.8081810445731825\n","Recall: 0.808051898492654\n","F1 Score: 0.8078855834835477\n","Confusion Matrix:\n","[[2859  231  380]\n"," [ 273 2911  302]\n"," [ 486  340 2700]]\n","--------------------------------\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.7782865865292883\n","Precision: 0.7814316116235847\n","Recall: 0.7782865865292883\n","F1 Score: 0.7780147757732555\n","Confusion Matrix:\n","[[2827  276  367]\n"," [ 421 2828  237]\n"," [ 641  382 2503]]\n","--------------------------------\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"eGKvuUYS9UeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mfcc"],"metadata":{"id":"YnzQuVJ59VIx"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    mel_spec_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    mfcc = librosa.feature.mfcc(y=adjusted_audio_signal, sr=SR, n_mfcc=23)\n","                    mean_mfcc = np.mean(mfcc, axis=-1)\n","\n","                    mel_spec_data.append(mean_mfcc)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    mel_spec_data = tf.keras.preprocessing.sequence.pad_sequences(mel_spec_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_mel_spec = np.mean(mel_spec_data)\n","    std_mel_spec = np.std(mel_spec_data)\n","    normalized_mel_spec_data = (mel_spec_data - mean_mel_spec) / std_mel_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples\n","          ,\"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_mel_spec_data, labels\n"],"metadata":{"id":"RdyxzusT9XGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mfcc_data, labels_mfcc = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n","\n","# Convert one-hot encoded labels to 1D array\n","y_labels = np.argmax(labels_mfcc, axis=1)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(mfcc_data, y_labels, test_size=0.2, random_state=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QFi4Q8rw9ynf","executionInfo":{"status":"ok","timestamp":1689417031650,"user_tz":-330,"elapsed":553612,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"2f68260e-4773-4bf6-8340-6c1cc8d3214a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470 \n","Aircraft samples: 17470\n"]}]},{"cell_type":"code","source":["for model_name in model_names:\n","  train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yz3f3hY3-AJs","executionInfo":{"status":"ok","timestamp":1689417063760,"user_tz":-330,"elapsed":32112,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"b63ce162-feaa-4bb0-ea83-a6b97d17cf9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: SVM\n","Accuracy: 0.940660179355085\n","Precision: 0.9414153173301337\n","Recall: 0.940660179355085\n","F1 Score: 0.9408167988886603\n","Confusion Matrix:\n","[[3409   11   50]\n"," [   2 3155  329]\n"," [  20  210 3296]]\n","--------------------------------\n","\n","Model: Random Forest\n","Accuracy: 0.9758633848502194\n","Precision: 0.9760549057011368\n","Recall: 0.9758633848502194\n","F1 Score: 0.9759038387402049\n","Confusion Matrix:\n","[[3438    2   30]\n"," [   0 3354  132]\n"," [  11   78 3437]]\n","--------------------------------\n","\n","Model: Naive Bayes\n","Accuracy: 0.7706544552566305\n","Precision: 0.7986387335990769\n","Recall: 0.7706544552566305\n","F1 Score: 0.7727180492093898\n","Confusion Matrix:\n","[[2929  104  437]\n"," [  23 2119 1344]\n"," [ 100  396 3030]]\n","--------------------------------\n","\n","Model: Decision Trees\n","Accuracy: 0.9308338103415379\n","Precision: 0.9309911966858734\n","Recall: 0.9308338103415379\n","F1 Score: 0.9309048762862886\n","Confusion Matrix:\n","[[3370   27   73]\n"," [  29 3182  275]\n"," [  50  271 3205]]\n","--------------------------------\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.9553520320549513\n","Precision: 0.9553560833194448\n","Recall: 0.9553520320549513\n","F1 Score: 0.9553365407091062\n","Confusion Matrix:\n","[[3438    7   25]\n"," [   5 3297  184]\n"," [  29  218 3279]]\n","--------------------------------\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ikHZCckP-JGz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ZCR"],"metadata":{"id":"brIGnYN5-Jhb"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    zcr_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    zcr = librosa.feature.zero_crossing_rate(y=adjusted_audio_signal, frame_length=SR, hop_length=SR)\n","                    mean_zcr = np.mean(zcr, axis=-1)\n","\n","                    zcr_data.append(mean_zcr)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    zcr_data = np.array(zcr_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_zcr = np.mean(zcr_data)\n","    std_zcr = np.std(zcr_data)\n","    normalized_zcr_data = (zcr_data - mean_zcr) / std_zcr\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_zcr_data, labels\n","\n"],"metadata":{"id":"RueZhU9--LR7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zcr_data, labels_zcr = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9QiynhS-0jS","executionInfo":{"status":"ok","timestamp":1689417710804,"user_tz":-330,"elapsed":59031,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"03dca2d4-8767-4bd1-8ce2-1e719f324800"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470 \n","Aircraft samples: 17470\n"]}]},{"cell_type":"code","source":["# Convert one-hot encoded labels to 1D array\n","y_labels = np.argmax(labels_zcr, axis=1)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(zcr_data, y_labels, test_size=0.2, random_state=42)"],"metadata":{"id":"leckzMYW-3Dn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_name in model_names:\n","  train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcrmL-Py-9cX","executionInfo":{"status":"ok","timestamp":1689417828396,"user_tz":-330,"elapsed":117594,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"ce93a88d-5280-4a1f-c46a-a9c21fd6b7d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: SVM\n","Accuracy: 0.5012402213318069\n","Precision: 0.5313582166338048\n","Recall: 0.5012402213318069\n","F1 Score: 0.4829257823276514\n","Confusion Matrix:\n","[[1430  813 1227]\n"," [ 410  988 2088]\n"," [ 185  505 2836]]\n","--------------------------------\n","\n","Model: Random Forest\n","Accuracy: 0.4673726388093875\n","Precision: 0.46932079023117906\n","Recall: 0.4673726388093875\n","F1 Score: 0.46760046640609054\n","Confusion Matrix:\n","[[1703  996  771]\n"," [ 850 1370 1266]\n"," [ 597 1103 1826]]\n","--------------------------------\n","\n","Model: Naive Bayes\n","Accuracy: 0.4956115245182217\n","Precision: 0.5366924480335443\n","Recall: 0.4956115245182217\n","F1 Score: 0.48085341795939673\n","Confusion Matrix:\n","[[1322 1008 1140]\n"," [ 347 1095 2044]\n"," [  98  650 2778]]\n","--------------------------------\n","\n","Model: Decision Trees\n","Accuracy: 0.4671818355275711\n","Precision: 0.467359551400327\n","Recall: 0.4671818355275711\n","F1 Score: 0.4666669687474248\n","Confusion Matrix:\n","[[1903  962  605]\n"," [1050 1417 1019]\n"," [ 773 1176 1577]]\n","--------------------------------\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.4685174585002862\n","Precision: 0.46857598220159447\n","Recall: 0.4685174585002862\n","F1 Score: 0.4665972459192154\n","Confusion Matrix:\n","[[2008  917  545]\n"," [1152 1392  942]\n"," [ 847 1168 1511]]\n","--------------------------------\n","\n"]}]},{"cell_type":"markdown","source":["# psd"],"metadata":{"id":"lJys47YO_aW1"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    log_psd_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Compute log PSD instead of MFCC\n","                    psd = np.abs(np.fft.fft(adjusted_audio_signal)) ** 2\n","                    log_psd = 10 * np.log10(psd)\n","\n","                    log_psd_data.append(log_psd)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    log_psd_data = tf.keras.preprocessing.sequence.pad_sequences(log_psd_data)\n","    labels = np.asarray(labels)\n","\n","    mean_log_psd = np.mean(log_psd_data)\n","    std_log_psd = np.std(log_psd_data)\n","    normalized_log_psd_data = (log_psd_data - mean_log_psd) / std_log_psd\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_log_psd_data, labels\n"],"metadata":{"id":"JyjNMveS_cIE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# less ram\n","import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    mean_log_psd = 0.0\n","    std_log_psd = 0.0\n","    count_log_psd = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            # Load signal and noise data for current file\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = noise_data[:w]\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    # Compute log PSD instead of MFCC\n","                    psd = np.abs(np.fft.fft(adjusted_audio_signal)) ** 2\n","                    log_psd = 10 * np.log10(psd)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","                    # Compute running mean and standard deviation\n","                    count_log_psd += 1\n","                    delta = log_psd - mean_log_psd\n","                    mean_log_psd += delta / count_log_psd\n","                    delta2 = log_psd - mean_log_psd\n","                    std_log_psd += delta * delta2\n","\n","            # Clear memory for current file\n","            del signal_data, noise_data\n","\n","    if count_log_psd == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    std_log_psd = np.sqrt(std_log_psd / count_log_psd)\n","\n","    # Normalize log PSD values on-the-fly\n","    normalized_log_psd_data = []\n","    for file_name in os.listdir(main_folder_path):\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=None, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = noise_data[:w]\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","                    # Compute log PSD instead of MFCC\n","                    psd = np.abs(np.fft.fft(adjusted_audio_signal)) ** 2\n","                    log_psd = 10 * np.log10(psd)\n","\n","                    # Normalize log PSD values on-the-fly\n","                    normalized_log_psd = (log_psd - mean_log_psd) / std_log_psd\n","                    normalized_log_psd_data.append(normalized_log_psd)\n","\n","    normalized_log_psd_data = tf.keras.preprocessing.sequence.pad_sequences(normalized_log_psd_data)\n","    labels = np.asarray(labels)\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_log_psd_data, labels\n"],"metadata":{"id":"OeVnBQwQQRJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["psd_data, labels = mix_audio(dataset_dir, ambient_path, 1, 44100)"],"metadata":{"id":"a3tD8J1n_gYc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(psd_data, labels, test_size=0.2, random_state=42)\n"],"metadata":{"id":"VevjG72Y_kqd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.impute import SimpleImputer\n","\n","# Create an imputer to handle missing values\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Apply imputation to training data\n","X_train = imputer.fit_transform(X_train)"],"metadata":{"id":"nRJEGWb2_orF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_name in model_names:\n","  train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)"],"metadata":{"id":"W7IfIV9A_pRF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Spectral Centroid"],"metadata":{"id":"kyyRxAznJRQT"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR, Limit):\n","    spec_centroid_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","            signal_data, sr = librosa.load(file_path, sr=44100, duration=1747)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=44100, duration=2640)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[0:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[0:w]))\n","            else:\n","                pass\n","\n","            N = int(len(signal_data) / segment_sr_required)\n","\n","            for i in range(N):\n","                start = i * segment_sr_required\n","                end = start + segment_sr_required\n","\n","                if end - start != SR:\n","                    continue\n","\n","                segment = signal_data[start:end]\n","                start_noise = np.random.randint(0, N-1) * segment_sr_required\n","                end_noise = start_noise + segment_sr_required\n","\n","                if end_noise - start_noise != SR:\n","                    continue\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    spec_centroid = librosa.feature.spectral_centroid(y=adjusted_audio_signal, sr=SR)\n","                    log_spec_centroid = np.log10(spec_centroid)\n","\n","                    spec_centroid_data.append(log_spec_centroid)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    spec_centroid_data = tf.keras.preprocessing.sequence.pad_sequences(spec_centroid_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_spec_centroid = np.mean(spec_centroid_data)\n","    std_spec_centroid = np.std(spec_centroid_data)\n","    normalized_spec_centroid_data = (spec_centroid_data - mean_spec_centroid) / std_spec_centroid\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples\n","          ,\"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_spec_centroid_data, labels\n"],"metadata":{"id":"HhZx8bxDJTr0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["normalized_spec_centroid_data, labels = mix_audio(dataset_dir, ambient_path, 1, 44100, 21000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvNHy6XFJYNS","executionInfo":{"status":"ok","timestamp":1689418701892,"user_tz":-330,"elapsed":212438,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"720fe265-337d-46e9-c18b-107cd16f37c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 17470 \n","Swarm Drone samples: 17470 \n","Aircraft samples: 17470\n"]}]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.impute import SimpleImputer\n","import numpy as np\n","\n","# Reshape normalized_spec_centroid_data to have 2 dimensions\n","X_train = normalized_spec_centroid_data.reshape(normalized_spec_centroid_data.shape[0], -1)\n","\n","# Convert one-hot encoded labels to 1-dimensional array\n","y = np.argmax(labels, axis=1)\n","\n","# Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.2, random_state=42)\n","\n","# Create an imputer to handle missing values\n","imputer = SimpleImputer(strategy='mean')\n","\n","# Apply imputation to training data\n","X_train = imputer.fit_transform(X_train)"],"metadata":{"id":"d_txPSTaJaxi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for model_name in model_names:\n","  train_and_evaluate_model(X_train, y_train, X_test, y_test, model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zPT1bjpANlT9","executionInfo":{"status":"ok","timestamp":1689419235546,"user_tz":-330,"elapsed":308073,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"0fa3fa11-f11b-4c9d-c545-4da34ec13d3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: SVM\n","Accuracy: 0.44657508109139477\n","Precision: 0.737974325565513\n","Recall: 0.44657508109139477\n","F1 Score: 0.3832109984442644\n","Confusion Matrix:\n","[[ 616 2840   14]\n"," [   9 3404   73]\n"," [  20 2845  661]]\n","--------------------------------\n","\n","Model: Random Forest\n","Accuracy: 0.44762449914138525\n","Precision: 0.7454924323132022\n","Recall: 0.44762449914138525\n","F1 Score: 0.38524012962544846\n","Confusion Matrix:\n","[[ 619 2835   16]\n"," [   6 3401   79]\n"," [   3 2851  672]]\n","--------------------------------\n","\n","Model: Naive Bayes\n","Accuracy: 0.4390383514596451\n","Precision: 0.7271998395903105\n","Recall: 0.4390383514596451\n","F1 Score: 0.37407418004137866\n","Confusion Matrix:\n","[[ 586 2874   10]\n"," [  16 3374   96]\n"," [  13 2871  642]]\n","--------------------------------\n","\n","Model: Decision Trees\n","Accuracy: 0.4425682121732494\n","Precision: 0.7431085670563256\n","Recall: 0.4425682121732494\n","F1 Score: 0.3761682941348525\n","Confusion Matrix:\n","[[ 617 2840   13]\n"," [   9 3414   63]\n"," [  12 2906  608]]\n","--------------------------------\n","\n","Model: k-Nearest Neighbors\n","Accuracy: 0.44333142530051517\n","Precision: 0.7405351563372036\n","Recall: 0.44333142530051517\n","F1 Score: 0.37851364080564714\n","Confusion Matrix:\n","[[ 605 2851   14]\n"," [  12 3401   73]\n"," [   8 2877  641]]\n","--------------------------------\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RIIU7TSiNr5t"},"execution_count":null,"outputs":[]}]}