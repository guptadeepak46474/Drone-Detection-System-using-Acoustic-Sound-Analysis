{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["2FreMCLuoHli","uzHfyrTDoVtk","dwdgSEtAqZX4","bXb0MkOTx0NI","7a23lZF5zQ0s","mTlC7wE57mHo","2rckR0pvBytH","OSR-WwsvE8nd","hXTXaDWBHI-G"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Global Code"],"metadata":{"id":"2FreMCLuoHli"}},{"cell_type":"code","source":[],"metadata":{"id":"couwfA7fbhMP","executionInfo":{"status":"ok","timestamp":1689541832269,"user_tz":-330,"elapsed":501,"user":{"displayName":"grey matter","userId":"10604083454161431627"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import os\n","import librosa\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import adjusted_rand_score\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import silhouette_score\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","import tensorflow as tf\n","import librosa as lr\n","import soundfile as sf\n","import scipy.signal as sig\n","from random import random, randint, shuffle\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n"],"metadata":{"id":"1iK4-dhVL-nZ","executionInfo":{"status":"ok","timestamp":1689541838296,"user_tz":-330,"elapsed":5514,"user":{"displayName":"grey matter","userId":"10604083454161431627"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["dataset_dir = '/content/drive/MyDrive/iit_our_rec/'\n","ambient_path = '/content/drive/MyDrive/iit_our_rec/noise_44min.wav'"],"metadata":{"id":"KectZa9pVZ1k","executionInfo":{"status":"ok","timestamp":1689541838297,"user_tz":-330,"elapsed":15,"user":{"displayName":"grey matter","userId":"10604083454161431627"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# List of durations to test\n","durations = [0.1, 0.2, 0.4, 0.6, 0.8, 1.0]\n","SR = 44100  # Sample rate"],"metadata":{"id":"seDhRZhKsFF4","executionInfo":{"status":"ok","timestamp":1689541838299,"user_tz":-330,"elapsed":13,"user":{"displayName":"grey matter","userId":"10604083454161431627"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Mel Spec"],"metadata":{"id":"uzHfyrTDoVtk"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    mel_spec_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    segment_mel_spec = librosa.feature.melspectrogram(\n","                        y=adjusted_audio_signal, sr=SR, n_fft=2048, hop_length=512, win_length=1024, n_mels=256\n","                    )\n","                    mean_of_mel = np.mean(segment_mel_spec, axis=-1)\n","\n","                    mel_spec_data.append(mean_of_mel)\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(mel_spec_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    mel_spec_data = tf.keras.preprocessing.sequence.pad_sequences(mel_spec_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_mel_spec = np.mean(mel_spec_data)\n","    std_mel_spec = np.std(mel_spec_data)\n","    normalized_mel_spec_data = (mel_spec_data - mean_mel_spec) / std_mel_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_mel_spec_data, labels\n"],"metadata":{"id":"t9F_qoVVP4-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ki1-vgvO6pm7"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UTXf09cxLgQY"},"outputs":[],"source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_mel_spec_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_mel_spec_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    y_pred = svm.predict(X_test)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"]},{"cell_type":"code","source":[],"metadata":{"id":"BVRQBzv3MAIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"8T0_hmREqZEc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mfcc"],"metadata":{"id":"dwdgSEtAqZX4"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    mfcc_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Replace Mel spectrogram calculation with MFCC calculation\n","                    segment_mfcc = librosa.feature.mfcc(\n","                        y=adjusted_audio_signal, sr=SR, n_fft=2048, hop_length=512, n_mfcc=13\n","                    )\n","                    mean_of_mfcc = np.mean(segment_mfcc, axis=-1)\n","\n","                    # Append MFCC features instead of Mel spectrogram features\n","                    mfcc_data.append(mean_of_mfcc)\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(mfcc_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad MFCC data instead of Mel spectrogram data\n","    mfcc_data = tf.keras.preprocessing.sequence.pad_sequences(mfcc_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_mfcc_spec = np.mean(mfcc_data)\n","    std_mel_spec = np.std(mfcc_data)\n","    normalized_mfcc_spec_data = (mfcc_data - mean_mfcc_spec) / std_mel_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_mfcc_spec_data, labels\n"],"metadata":{"id":"DX4inq8pqbzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_mfcc_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_mfcc_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    y_pred = svm.predict(X_test)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")\n"],"metadata":{"id":"sueXFOrOq9xR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bfJ-xmK6sLV9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# psd with log base 10"],"metadata":{"id":"bXb0MkOTx0NI"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    psd_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Replace MFCC calculation with PSD calculation\n","                    stft = librosa.core.stft(adjusted_audio_signal)\n","                    psd = np.abs(stft) ** 2\n","                    log_psd = np.log10(psd + 1e-10)  # Logarithm (base 10) of PSD values\n","\n","                    # Append log PSD features instead of MFCC features\n","                    psd_data.append(log_psd)\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(psd_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad log PSD data instead of MFCC data\n","    psd_data = tf.keras.preprocessing.sequence.pad_sequences(psd_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_psd_spec = np.mean(psd_data)\n","    std_psd_spec = np.std(psd_data)\n","    normalized_psd_spec_data = (psd_data - mean_psd_spec) / std_psd_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_psd_spec_data, labels\n"],"metadata":{"id":"Zc5XGoYzsOr-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_psd_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_psd_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Reshape X_train to have two dimensions\n","    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train_2d, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n","    y_pred = svm.predict(X_test_2d)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"],"metadata":{"id":"LckfT9veyCVv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# psd without log base 10"],"metadata":{"id":"7a23lZF5zQ0s"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    psd_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Replace MFCC calculation with PSD calculation\n","                    stft = librosa.core.stft(adjusted_audio_signal)\n","                    psd = np.abs(stft) ** 2\n","\n","                    # Append PSD features instead of MFCC features\n","                    psd_data.append(psd)\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(psd_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad PSD data instead of MFCC data\n","    psd_data = tf.keras.preprocessing.sequence.pad_sequences(psd_data)\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_psd_spec = np.mean(psd_data)\n","    std_psd_spec = np.std(psd_data)\n","    normalized_psd_spec_data = (psd_data - mean_psd_spec) / std_psd_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_psd_spec_data, labels\n"],"metadata":{"id":"H429kNVezV78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_psd_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_psd_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Reshape X_train to have two dimensions\n","    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train_2d, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n","    y_pred = svm.predict(X_test_2d)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"],"metadata":{"id":"duOWiQCQ4ogP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Spectral Centroid with log base 10"],"metadata":{"id":"mTlC7wE57mHo"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    spectral_centroid_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Calculate Spectral Centroid\n","                    spectral_centroids = librosa.feature.spectral_centroid(y=adjusted_audio_signal, sr=SR)\n","\n","                    # Take the logarithm (base 10) of the Spectral Centroid values\n","                    log_spectral_centroids = np.log10(spectral_centroids + 1e-10)\n","\n","                    # Append log Spectral Centroid features instead of PSD features\n","                    spectral_centroid_data.append(log_spectral_centroids)\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(spectral_centroid_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad Spectral Centroid data instead of PSD data\n","    spectral_centroid_data = tf.keras.preprocessing.sequence.pad_sequences(spectral_centroid_data)\n","\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_spec_spec = np.mean(spectral_centroid_data)\n","    std_spec_spec = np.std(spectral_centroid_data)\n","    normalized_spec_spec_data = (spectral_centroid_data - mean_spec_spec) / std_spec_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_spec_spec_data, labels\n"],"metadata":{"id":"Rs-vOpGY7plh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_spectral_centroid_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_spectral_centroid_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Reshape X_train to have two dimensions\n","    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train_2d, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n","    y_pred = svm.predict(X_test_2d)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"],"metadata":{"id":"ozG8v19p9sGL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"R7VppjI7BvZz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Spectral centroid without log base 10"],"metadata":{"id":"2rckR0pvBytH"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    spectral_centroid_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Calculate Spectral Centroid\n","                    spectral_centroids = librosa.feature.spectral_centroid(y=adjusted_audio_signal, sr=SR)\n","\n","                    # Append Spectral Centroid features instead of log Spectral Centroid features\n","                    spectral_centroid_data.append(spectral_centroids)\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(spectral_centroid_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad Spectral Centroid data instead of log Spectral Centroid data\n","    spectral_centroid_data = tf.keras.preprocessing.sequence.pad_sequences(spectral_centroid_data)\n","\n","\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_spec_spec = np.mean(spectral_centroid_data)\n","    std_spec_spec = np.std(spectral_centroid_data)\n","    normalized_spec_spec_data = (spectral_centroid_data - mean_spec_spec) / std_spec_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_spec_spec_data, labels\n"],"metadata":{"id":"4fY-aWlpB31Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_spectral_centroid_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_spectral_centroid_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Reshape X_train to have two dimensions\n","    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train_2d, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n","    y_pred = svm.predict(X_test_2d)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"],"metadata":{"id":"fabBFrgrEAMA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gLifPlxLE8V7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Zcr with log base 10"],"metadata":{"id":"OSR-WwsvE8nd"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    zcr_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Calculate Zero Crossing Rate\n","                    zcr = librosa.feature.zero_crossing_rate(y=adjusted_audio_signal)\n","\n","                    # Take the logarithm (base 10) of the Zero Crossing Rate values\n","                    log_zcr = np.log10(zcr + 1e-10)\n","\n","                    # Append log Zero Crossing Rate features instead of log Spectral Centroid features\n","                    zcr_data.append(log_zcr)\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(zcr_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad Zero Crossing Rate data instead of log Spectral Centroid data\n","    zcr_data = tf.keras.preprocessing.sequence.pad_sequences(zcr_data)\n","\n","\n","    labels = tf.keras.utils.to_categorical(labels, num_classes=3)\n","\n","    mean_zcr_spec = np.mean(zcr_data)\n","    std_zcr_spec = np.std(zcr_data)\n","    normalized_zcr_data = (zcr_data - mean_zcr_spec) / std_zcr_spec\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_zcr_data, labels\n"],"metadata":{"id":"Y-q2QqEsFAOp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_spectral_centroid_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_spectral_centroid_data, y_labels, test_size=0.2, random_state=42)\n","\n","    # Reshape X_train to have two dimensions\n","    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train_2d, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n","    y_pred = svm.predict(X_test_2d)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"],"metadata":{"id":"Ca-sBUtEHIPa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Zcr without log base 10"],"metadata":{"id":"hXTXaDWBHI-G"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","import os\n","import numpy as np\n","import librosa\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn import svm\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import RobustScaler\n","def mix_audio(main_folder_path, file_path_ambient, duration, SR):\n","    zcr_data = []\n","    labels = []\n","\n","    segment_sr_required = duration * SR\n","\n","    no_of_drone_samples = 0\n","    no_of_swarm_drone_samples = 0\n","    no_of_aircraft_samples = 0\n","\n","    for file_name in os.listdir(main_folder_path):\n","        if 'drone'.lower() in file_name.lower():\n","            flag = 0\n","        elif 'swarm'.lower() in file_name.lower():\n","            flag = 1\n","        elif 'aircraft'.lower() in file_name.lower():\n","            flag = 2\n","        else:\n","            continue\n","\n","        if file_name.endswith('.wav') or file_name.endswith('.WAV') or file_name.endswith('.mp3'):\n","            file_path = os.path.join(main_folder_path, file_name)\n","\n","            signal_data, sr = librosa.load(file_path, sr=None, mono=True)\n","            signal_data = signal_data / np.max(np.abs(signal_data))\n","            noise_data, sr_noise = librosa.load(file_path_ambient, sr=None, mono=True)\n","            noise_data = noise_data / np.max(np.abs(noise_data))\n","\n","            s = len(signal_data)\n","            n = len(noise_data)\n","\n","            if n > s:\n","                noise_data = noise_data[:s]\n","            elif s > n:\n","                w = s - n\n","                noise_data = np.concatenate((noise_data, noise_data[:w]))\n","            else:\n","                pass\n","\n","            N = int(s / segment_sr_required)\n","\n","            for i in range(N):\n","                start = int(i * segment_sr_required)\n","                end = int(start + segment_sr_required)\n","\n","                segment = signal_data[start:end]\n","                start_noise = int(i * segment_sr_required)\n","                end_noise = int(start_noise + segment_sr_required)\n","\n","                noise = noise_data[start_noise:end_noise]\n","\n","                rms_signal = np.mean(np.square(segment))\n","                rms_noise = np.mean(np.square(noise))\n","\n","                dbset = [-25, -20, -15, -10, -5, 0, 5, 10, 15, 20]\n","\n","                for j in range(len(dbset)):\n","                    rms_signal_req_to_increase = rms_noise / (10 ** (-dbset[j] / 10))\n","                    scaling_factor = np.sqrt(rms_signal_req_to_increase / rms_signal)\n","                    adjusted_audio_signal = segment * scaling_factor\n","\n","                    adjusted_audio_signal += noise\n","\n","\n","                    # Calculate Zero Crossing Rate\n","                    zcr = librosa.feature.zero_crossing_rate(y=adjusted_audio_signal)\n","\n","                    # Append Zero Crossing Rate features instead of log Zero Crossing Rate features\n","                    zcr_data.append(zcr[0])  # Extract the ZCR array from the 2D matrix\n","\n","                    labels.append(flag)\n","\n","                    if flag == 0:\n","                        no_of_drone_samples += 1\n","                    elif flag == 1:\n","                        no_of_swarm_drone_samples += 1\n","                    elif flag == 2:\n","                        no_of_aircraft_samples += 1\n","\n","    if len(zcr_data) == 0:\n","        raise ValueError(\"No audio data available for the given duration.\")\n","\n","    # Pad Zero Crossing Rate data instead of log Zero Crossing Rate data\n","    zcr_data = tf.keras.preprocessing.sequence.pad_sequences(zcr_data)\n","    zcr_data[np.isnan(zcr_data)] = 0  # Replace remaining NaN values with zero\n","\n","\n","    if np.count_nonzero(zcr_data) > 0:\n","        zcr_data[zcr_data == 0] = np.min(zcr_data[zcr_data != 0])  # Replace zero values with the minimum non-zero value\n","\n","    scaler = RobustScaler()\n","    normalized_zcr_data = scaler.fit_transform(zcr_data)\n","    labels = np.array(labels)  # Convert labels to a 1D array\n","\n","    print(\"Drone samples:\", no_of_drone_samples,\n","          \"\\nSwarm Drone samples:\", no_of_swarm_drone_samples,\n","          \"\\nAircraft samples:\", no_of_aircraft_samples)\n","\n","    return normalized_zcr_data, labels\n"],"metadata":{"id":"hC1cwy4qHMLk","executionInfo":{"status":"ok","timestamp":1689541925301,"user_tz":-330,"elapsed":519,"user":{"displayName":"grey matter","userId":"10604083454161431627"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Initialize a list to store accuracy values for each duration\n","accuracies = []\n","for duration in durations:\n","    # Call mix_audio function to get the data and labels\n","    normalized_zcr_data, labels = mix_audio(dataset_dir, ambient_path, duration, SR)\n","\n","    # Convert labels to 1D array\n","    # y_labels = np.argmax(labels, axis=1)\n","\n","    # Split data into train and test sets\n","    X_train, X_test, y_train_labels, y_test_labels = train_test_split(normalized_zcr_data, labels, test_size=0.2, random_state=42)\n","\n","    # Reshape X_train to have two dimensions\n","    # X_train_2d = X_train.reshape(X_train.shape[0], -1)\n","\n","    # Create and train SVM classifier\n","    svm = SVC(C=10, kernel='rbf', gamma='scale')\n","    svm.fit(X_train, y_train_labels)\n","\n","    # Predict and calculate accuracy\n","    # X_test_2d = X_test.reshape(X_test.shape[0], -1)\n","    y_pred = svm.predict(X_test)\n","    accuracy = accuracy_score(y_test_labels, y_pred)\n","\n","    # Append accuracy to the list\n","    accuracies.append(accuracy)\n","\n","# Print accuracy for each duration\n","for i, duration in enumerate(durations):\n","    print(f\"Duration: {duration} seconds - SVM Accuracy: {accuracies[i]}\")"],"metadata":{"id":"dHRjz8j0HbSm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689542315196,"user_tz":-330,"elapsed":39942,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"2e7e9927-43b6-42fb-c9eb-39e467595fd4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Drone samples: 3494 \n","Swarm Drone samples: 3494 \n","Aircraft samples: 3494\n","Duration: 1 seconds - SVM Accuracy: 0.3218884120171674\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5bbxkKHqifLf","executionInfo":{"status":"ok","timestamp":1689541828983,"user_tz":-330,"elapsed":24119,"user":{"displayName":"grey matter","userId":"10604083454161431627"}},"outputId":"a8f4dda7-0e2a-4ccd-8966-6af331ec882c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}